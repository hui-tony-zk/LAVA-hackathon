---
title: "Final_Analysis.Rmd"
author: "Tony Hui"
date: "October 24, 2015"
output: 
  html_document: 
    keep_md: yes
    self_contained: no
    toc: yes
---

# Introduction to us

## Team Members

* Tony Hui - MSc student in Genome Sciences
* Tyler Robb-smith - Physics PhD graduate
* Nathan Roberson - Statistics PhD graduate
* Renee Mak - Freelance graphic designer

# Prelimary analysis of the Data

## Load dependencies and Data

```{r}
require(knitr)
opts_chunk$set(echo=F)
```

```{r warning=FALSE, error=FALSE}
suppressPackageStartupMessages(require(ggplot2))
suppressPackageStartupMessages(require(dplyr))
suppressPackageStartupMessages(require(stringr))
suppressPackageStartupMessages(require(tidyr))
suppressPackageStartupMessages(require(data.table))
suppressPackageStartupMessages(require(ggplot2))
```

```{r}
files <- dir(path = "ObservationFiles/")

read_files <- function(x) {
  filename <- x
  file_metadata_info <- str_split_fixed(gsub(".csv", "", filename), pattern = "-", n = 4) %>% 
    c() %>% 
    str_replace(pattern = "Course|Instr|Semester|Observation", replacement = "")
  
  file <- read.csv(paste0("ObservationFiles/", x))
  colnames(file)[1] <- "time" # first column is time, but it is unlabeled
  file <- file[1:length(levels(file$time))-1,]
  file$time <- 1:nrow(file) *2
  if (ncol(file) > 26) {
    file <- file %>% select(-starts_with("X")) # some columns have a shit-tonne of extra columns, presumably due to excel export error...
  }
  file$course <- file_metadata_info[1]
  file$instructor <- file_metadata_info[2]
  file$semester <- file_metadata_info[3]
  file$observation <- file_metadata_info[4]
  file$year <- substr(file$course, start = 1, stop = 1)
  return(file)
}

all_files <- lapply(files, read_files)
names(all_files) <- files
```

### Sneak peak at the data

```{r}
lapply(all_files, ncol) %>% unlist %>% unique()
lapply(all_files, nrow) %>% unlist %>% unique() %>% sort()
```

Number of rows/columns all over the place - assume that there should only be 26 "real" columns (plus the 4 columns of metadata that was added) - use this function to figure out what's wrong.

```{r eval=FALSE}
(outliers_column <- all_files[lapply(all_files, ncol) == 31] %>% names)
read.csv(paste0("ObservationFiles/", outliers_column[1])) %>% colnames

(outliers_row <- all_files[lapply(all_files, nrow) == 16] %>% names)
read.csv(paste0("ObservationFiles/", outliers_row[1])) %>% View
```

### Issue fixed - went back and fixed the read file function and combined all data

```{r}
all_files_clean <- rbindlist(all_files) %>% as.data.frame()
all_files_clean[is.na(all_files_clean)] <- 0
all_files_clean %>% head() %>% kable(format = "markdown")
```

### Merge in class performance levels

#### Read in the file

```{r}
class_perform <- read.csv("StudentPerformance.csv") %>%
  separate(ClassSection, into = c("course", "instructor", "semester"), sep = "-")

class_perform$course <- str_replace(class_perform$course, pattern = "Course", replacement = "")
class_perform$instructor <- str_replace(class_perform$instructor, pattern = "Instr", replacement = "")
class_perform$semester <- str_replace(class_perform$semester, pattern = "Semester", replacement = "")

class_perform %>% head() %>% kable(format = "markdown")
```

#### Merge with the rest

```{r}
all_files_clean_marks <- full_join(all_files_clean, class_perform)
write.csv(x = all_files_clean_marks, file = "all_observations_cleaned.csv", quote = F, row.names = F)
```

# Basic exploratory analysis

## Fractional amount of time spent on each category overall

```{r}
gathered_values <- all_files_clean %>% 
  tbl_df() %>%
  gather(key = measure, value = value, -(course:year), -time, na.rm = T)

gathered_values %>% 
  group_by(measure) %>%
  summarize(frac_time = sum(value)/n()) %>%
  ggplot(aes(y = frac_time, x = reorder(measure, frac_time)))+
  geom_point() + 
  xlab("Activitiy") + 
  coord_flip() +
  theme_bw()
```

## Fractional amount of time spent on each category overall per class year

```{r}
gathered_values %>% 
  group_by(year, measure) %>%
  summarize(frac_time = sum(value)/n()) %>%
  ggplot(aes(y = frac_time, x = reorder(measure, frac_time), group = year, color = year))+
  geom_point() + 
  geom_line() +
  xlab("Activitiy") + 
  # facet_wrap(~ year, nrow = 1) + 
  coord_flip() +
  theme_bw()
```

## Number of different instructor-semester pairings per course

```{r}
all_files_clean_marks[,c("course", "instructor", "semester")] %>%
  unique() %>%
  group_by(course) %>%
  tally() %>%
  ggplot(aes(reorder(course, n), n)) +
    geom_bar(stat = "identity") +
    xlab("Course ID") +
    theme_bw()
```

## Fractional amount of time spent on each category for course `12`, `21`, and `11`, further granuarized by instructor

The labels in each box represents the course id

```{r, fig.width=10}
gathered_values %>% 
  filter(course == 21 | course == 12 | course == 11) %>%
  group_by(course, instructor, measure) %>%
  summarize(frac_time = sum(value)/n()) %>%
  ggplot(aes(y = frac_time, x = reorder(measure, frac_time), color = instructor, group = instructor))+
  geom_line() + 
  xlab("Activitiy") + 
  facet_wrap(~ course, nrow = 1) + 
  coord_flip() +
  theme_bw()
```


## Time spent on lecture vs student growth

All courses - each dot is one course (separated by year level)

```{r student_perf_vs_lecture_time}
student_perf_vs_lecture_time <- all_files_clean_marks %>%
  group_by(course, instructor, semester) %>%
  summarize(
    num_obs = n(),
    num_lecture = sum(Instructor.Lecturing, na.rm = T),
    student_performance = mean(StudentPerformance.SectionAverage)
  ) %>%
  mutate(percent_time = num_lecture / num_obs, course_level = paste0("year", substr(course, start = 1, stop = 1)))

student_perf_vs_lecture_time %>%
  ggplot(aes(x = student_performance, y = percent_time)) +
    facet_wrap(~ course_level) + 
    geom_point() +
    geom_smooth(method = "lm", se = F) +
    ylab("Fraction of time spent on lecturing") +
    xlab("Gain in student performance") +
    theme_bw()
```

Looks like there's a positive correlation with lecture time and student performance in first year classes, and a negative correlation in second year classes

# Question 1: Which activities (individually) has an effect on student performance?

## Plot the variation of each measure for a single course and compare across instructors-semester pairings

It really doesn't make sense to look across courses since different courses have different content = different methods of learning - scientific method: only vary one variable at a time.

### Plot the variation of each measure for course 12 between instructors-semester pairings

```{r}
course_of_interest = c(11, 12, 21)

ind_predictors <- all_files_clean_marks %>% 
  tbl_df() %>%
  gather(key = measure, value = value, -(course:ClassSize), -time) %>%
  filter(course %in% course_of_interest) %>%
  group_by(course, instructor, semester, measure, StudentPerformance.SectionAverage, StudentPerformance.StandardError) %>%
  summarize(frac_time = sum(value)/n())

ind_predictors_variability <- ind_predictors %>%
  group_by(course, measure) %>%
  summarize(mean_frac_time = mean(frac_time), sd_frac_time = sd(frac_time)) %>%
  arrange(desc(sd_frac_time))

ggplot(ind_predictors_variability, aes(x = reorder(measure, sd_frac_time), y = mean_frac_time)) +
  geom_point() +
  geom_errorbar(aes(ymin = mean_frac_time - sd_frac_time, ymax = mean_frac_time + sd_frac_time)) +
  coord_flip() +
  facet_wrap(~ course) +
  xlab("Fraction of class time spent\n(error bars represents standard deviation") +
  theme_bw()
```

## Plot correlation between the top 3 variable activities

```{r width=10}
inner_join(
  ind_predictors, 
  ind_predictors_variability %>% arrange(desc(sd_frac_time)) %>% do(head(., 5))
  ) %>%
  ggplot(aes(StudentPerformance.SectionAverage, frac_time)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  facet_grid(course ~ measure, scales = "free") +
  theme_bw()
```


# Question 2: Which activities (individually) explains the largest variability in student performance across all courses?

### Multiple linear regression

#### Transform data for regression modelling

```{r}
summary_of_fract_time_spent <- all_files_clean_marks %>% 
  tbl_df() %>%
  gather(key = measure, value = value, -(course:ClassSize), -time) %>%
  group_by(course, instructor, semester, measure, StudentPerformance.SectionAverage, StudentPerformance.StandardError) %>%
  summarize(frac_time = sum(value)/n()) %>%
  spread(key = measure, value = frac_time)

write.csv(x = summary_of_fract_time_spent, file = "summary_of_fract_time_spent.csv", quote = F, row.names = F)

summary_of_fract_time_spent %>% head() %>% kable(format = "markdown")
```

#### Predicting student performance as a function of all our variables

```{r}
# course_of_interest <- c(11, 12)
course_of_interest <- unique(summary_of_fract_time_spent$course)

predicting_variables <- colnames(summary_of_fract_time_spent)[-(1:5)]
model <- glm(
  formula = as.formula(paste("StudentPerformance.SectionAverage ~ ",paste(predicting_variables, collapse= "+"))), 
  data = summary_of_fract_time_spent %>% filter(course %in% course_of_interest)
  )

summary(model)
```

#### Take only the dimensions that are significant (top 6)

```{r}
p_values <- coef(summary(model)) %>%
  as.data.frame() %>%
  add_rownames("id") %>%
  filter(!grepl("Intercept", id)) %>%
  setnames(colnames(.), c("id", "estimate", "stderr", "tval", "pval")) %>%
  arrange(pval)

p_values %>% head(6) %>% kable(format = "markdown")

predicting_variables <- p_values$id[1:6]
```

#### Looking at how these variables predict student performance

```{r}
all_classes_performance <- all_files_clean_marks %>% 
  tbl_df() %>%
  gather(key = measure, value = value, -(course:ClassSize), -time) %>%
  group_by(course, year,instructor, semester, measure, StudentPerformance.SectionAverage, StudentPerformance.StandardError) %>%
  summarize(frac_time = sum(value)/n()) %>%
  filter(measure %in% predicting_variables)

all_classes_performance %>%
  ggplot(aes(StudentPerformance.SectionAverage, frac_time)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)  +
  facet_wrap(~ measure, scales = "free_y") +
  theme_bw()
```

Conclusion: cannot compare across courses

# Question 3 - which classes are arranged such that they have similar amounts of time spent on each activity?

## Focusing on course 12 for now

```{r}
require(gplots)
variable_dimensions <- ind_predictors_variability %>% 
  filter(sd_frac_time > 0) %>%
  group_by(measure) %>%
  tally() %>%
  filter(n == 3)

cluster_setup <- all_files_clean_marks %>% 
  tbl_df() %>%
  filter(course == 12 | course == 11) %>%
  gather(key = measure, value = value, -(course:ClassSize), -time) %>%
  filter(measure %in% variable_dimensions$measure) %>%
  droplevels() %>%
  group_by(course, instructor, measure, StudentPerformance.SectionAverage) %>%
  summarize(frac_time = sum(value)/n()) 

normalize_to_01 <- function(x) (x - min(x))/(max(x) - min(x))

cluster_normalized <- cluster_setup %>% 
  ungroup() %>%
  group_by(measure) %>%
  # mutate(normalized_measure = (frac_time - mean(frac_time))/sd(frac_time)) %>%
  mutate(normalized_measure = normalize_to_01(frac_time)) %>%
  group_by(course, instructor, StudentPerformance.SectionAverage) %>%
  select(-frac_time) %>%
  spread(key = measure, value = normalized_measure)

cluster_matrix <- cluster_normalized %>%
  select(-instructor, -course, -StudentPerformance.SectionAverage) %>% data.matrix()

rownames(cluster_matrix) <- cluster_normalized$instructor

cluster_matrix <- t(cluster_matrix)
```

```{r}
mydist <- function(x) dist(x, method = "euclidian")
myhclust <- function(x) hclust(x, method = "ward.D")

# , "#5e4fa2"
nbreaks = 11
colors = colorRampPalette(c("#f03b20", "#ffffcc"), bias = 1)(nbreaks)

label_colors <- c("#ffffb2", "#fecc5c", "#fd8d3c", "#f03b20", "#bd0026")

```

NOTE: The gradient labels represents the students performance, normalized between 0 to 1. Brown = low, purple = high (values normalized between 0 to 1)

```{r, fig.height=8, fig.width=8}
# png(file = "heatmap2.png")
norm_perform <- normalize_to_01(cluster_normalized$StudentPerformance.SectionAverage)
gradient_pallete <- colorRampPalette(c("#b35806", "#f7f7f7", "#542788"))(100)
norm_values <- round(norm_perform, 2) * 100
norm_values[norm_values == 0] <- 1

heatmap.2(cluster_matrix,
          distfun=mydist,
          hclustfun=myhclust,
          ColSideColors = gradient_pallete[norm_values],
          dendrogram = "both",
          Rowv=reorder(as.dendrogram(myhclust(mydist(cluster_matrix))), wts = 1:ncol(cluster_matrix)),
          col = colors,
          trace = "none",
          margins = c(4,12))
# dev.off()
```

## What about across all courses?

```{r}
cluster_setup <- all_files_clean_marks %>% 
  tbl_df() %>%
  # filter(course == 12 | course == 11) %>%
  gather(key = measure, value = value, -(course:ClassSize), -time) %>%
  filter(measure %in% variable_dimensions$measure) %>%
  droplevels() %>%
  group_by(course, instructor, measure, StudentPerformance.SectionAverage) %>%
  summarize(frac_time = sum(value)/n()) 

normalize_to_01 <- function(x) (x - min(x))/(max(x) - min(x))

cluster_normalized <- cluster_setup %>% 
  ungroup() %>%
  group_by(measure) %>%
  # mutate(normalized_measure = (frac_time - mean(frac_time))/sd(frac_time)) %>%
  mutate(normalized_measure = normalize_to_01(frac_time)) %>%
  group_by(course, instructor, StudentPerformance.SectionAverage) %>%
  select(-frac_time) %>%
  spread(key = measure, value = normalized_measure)

cluster_matrix <- cluster_normalized %>%
  select(-instructor, -course, -StudentPerformance.SectionAverage) %>% data.matrix()

rownames(cluster_matrix) <- cluster_normalized$instructor

cluster_matrix <- t(cluster_matrix)

mydist <- function(x) dist(x, method = "euclidian")
myhclust <- function(x) hclust(x, method = "ward.D")

# , "#5e4fa2"
nbreaks = 11
colors = colorRampPalette(c("#f03b20", "#ffffcc"), bias = 1)(nbreaks)

label_colors <- c("#ffffb2", "#fecc5c", "#fd8d3c", "#f03b20", "#bd0026")

```

```{r, fig.height=8, fig.width=8}
# png(file = "heatmap2.png")
norm_perform <- normalize_to_01(cluster_normalized$StudentPerformance.SectionAverage)
gradient_pallete <- colorRampPalette(c("#b35806", "#f7f7f7", "#542788"))(100)
norm_values <- round(norm_perform, 2) * 100
norm_values[norm_values == 0] <- 1

heatmap.2(cluster_matrix,
          distfun=mydist,
          hclustfun=myhclust,
          ColSideColors = gradient_pallete[norm_values],
          dendrogram = "both",
          Rowv=reorder(as.dendrogram(myhclust(mydist(cluster_matrix))), wts = 1:ncol(cluster_matrix)),
          col = colors,
          trace = "none",
          margins = c(4,12))
# dev.off()
```

